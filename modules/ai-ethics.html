<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>AI Foundations - Modules</title>

    <link
      rel="stylesheet"
      href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0/css/all.min.css"
    />

    <link rel="stylesheet" href="../css/modules-inner.css" />

    <link
      rel="stylesheet"
      href="https://cdn.jsdelivr.net/npm/sweetalert2@11/dist/sweetalert2.min.css"
    />
    <script src="https://cdn.jsdelivr.net/npm/sweetalert2@11"></script>

    <script
      src="https://code.jquery.com/jquery-3.6.0.min.js"
      integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4="
      crossorigin="anonymous"
    ></script>
  </head>
  <body>
    <nav>
        <img src="../img/logo.svg" class="logo" alt="MaxAI" />
      </a>

      <div class="navigation">
        <ul>
          <li><a href="../home.html">Home</a></li>
          <li><a href="../modules.html" class="active">Modules</a></li>
          <li><a href="../flashcard.html">Flashcard</a></li>
          <li><a href="../quiz.html">Quiz</a></li>
          <li><a href="../about.html">About Us</a></li>
        </ul>
        <div class="mobile-menu-btn" aria-label="Open menu" role="button" tabindex="0">
          <i class="fas fa-bars"></i>
        </div>
      </div>

      <div class="profile-menu">
        <button
          type="button"
          class="profile-btn"
          aria-label="Profile"
          aria-expanded="false"
        >
          <i class="fas fa-user"></i>
        </button>
        <div class="menu">
          <a href="../userprofile.html"
            ><i class="fas fa-user-circle"></i> Profile</a
          >
          <a href="../login.html"
            ><i class="fas fa-right-from-bracket"></i> Logout</a
          >
        </div>
      </div>
    </nav>
    <script src="../js/nav.js"></script>
    <script>
      // Mobile menu toggle for inner modules page
      (function(){
        const burger = document.querySelector('.mobile-menu-btn');
        const menuList = document.querySelector('nav .navigation ul');
        if (burger && menuList) {
          burger.addEventListener('click', function(){
            menuList.classList.toggle('active');
          });
          // Close menu when a link is tapped (mobile)
          menuList.querySelectorAll('a').forEach(a => a.addEventListener('click', () => {
            menuList.classList.remove('active');
          }));
        }
      })();
    </script>

    <section id="about-home">
      <div class="hero-content">
        <div class="hero-badge">
          <i class="fas fa-robot"></i>
          <span>Beginner Friendly</span>
        </div>
        <h1>AI Foundations</h1>
        <p class="hero-subtitle">
                Start your AI journey with fundamental concepts, machine
                learning basics, and practical applications.
        </p>
        <div class="hero-stats">
          <div class="stat-item">
            <i class="fas fa-clock"></i>
            <span>1-2 hours</span>
          </div>
          <div class="stat-item">
            <i class="fas fa-signal"></i>
            <span>Beginner</span>
          </div>
          <div class="stat-item">
            <i class="fas fa-users"></i>
            <span>Free</span>
          </div>
        </div>
      </div>
      <div class="hero-visual">
        <div class="floating-card card-1">
          <i class="fas fa-brain"></i>
          <span>ML</span>
        </div>
        <div class="floating-card card-2">
          <i class="fas fa-network-wired"></i>
          <span>Neural</span>
        </div>
        <div class="floating-card card-3">
          <i class="fas fa-chart-line"></i>
          <span>Data</span>
        </div>
      </div>
    </section>

    <section id="course-inner">
      <div class="overview">
        <div class="course-panel">
          <div class="course-header">
            <img
              class="course-img"
              src="../img/ai-ethics.png"
              alt="AI Foundations"
            />
            <div class="course-overlay">
              <div class="play-button">
                <i class="fas fa-play"></i>
              </div>
            </div>
          </div>

          <div class="course-info">
            <div class="course-meta">
              <div class="meta-item">
                <i class="fas fa-calendar"></i>
                <span>Last updated: Aug 2025</span>
              </div>
            </div>

            <div class="callout info">
              <i class="fas fa-lightbulb"></i>
              <div>
                <strong>Pro Tip:</strong> Complete one lesson per day for
                optimal retention. Each lesson builds on the previous one.
              </div>
            </div>
            <div class="progress-wrap">
              <div
                id="progress-bar"
                class="progress-bar"
                role="progressbar"
                aria-valuemin="0"
                aria-valuenow="0"
                aria-valuemax="100"
              >
                <div
                  id="progress-fill"
                  class="progress-fill"
                  style="width: 0%"
                ></div>
                <div id="progress-label" class="progress-label">
                  0% Completed
                </div>
              </div>
            </div>
          </div>
        </div>

        <div class="content-sections">
          <div class="reset-bar">
            <button id="reset-progress" class="reset-btn">
              <i class="fa-solid fa-rotate-left"></i> Reset Progress
            </button>
          </div>

          <!-- Learning Objectives ---->
          <section class="content-section" id="objectives">
            <div class="section-header">
              <div class="section-icon">
                <i class="fas fa-bullseye"></i>
              </div>
              <h3>Learning Objectives</h3>
            </div>
            <div class="objectives-grid">
              <div class="objective-item">
                <i class="fas fa-check-circle"></i>
                <span>Define AI vs. ML vs. DL and where each applies</span>
              </div>
              <div class="objective-item">
                <i class="fas fa-check-circle"></i>
                <span>Explain the Turing Test and discuss its limitations</span>
              </div>
              <div class="objective-item">
                <i class="fas fa-check-circle"></i>
                <span
                  >Differentiate Narrow AI (ANI), AGI, and
                  Superintelligence</span
                >
              </div>
              <div class="objective-item">
                <i class="fas fa-check-circle"></i>
                <span
                  >Describe data: features, labels, splits, and leakage</span
                >
              </div>
              <div class="objective-item">
                <i class="fas fa-check-circle"></i>
                <span
                  >Compare supervised, unsupervised, and reinforcement
                  learning</span
                >
              </div>
              <div class="objective-item">
                <i class="fas fa-check-circle"></i>
                <span
                  >Compute and interpret precision, recall, F1, and
                  ROC-AUC</span
                >
              </div>
              <div class="objective-item">
                <i class="fas fa-check-circle"></i>
                <span
                  >Identify overfitting and apply
                  regularization/validation</span
                >
              </div>
              <div class="objective-item">
                <i class="fas fa-check-circle"></i>
                <span>Apply basic search ideas (BFS/DFS, A* intuition)</span>
              </div>
              <div class="objective-item">
                <i class="fas fa-check-circle"></i>
                <span
                  >Practice responsible AI: fairness, privacy,
                  transparency</span
                >
              </div>
            </div>
          </section>

          <section class="content-section" id="prerequisites">
            <div class="section-header">
              <div class="section-icon">
                <i class="fas fa-list-check"></i>
              </div>
              <h3>Prerequisites</h3>
            </div>
            <p>
              Curiosity and basic computer literacy. Optional: light Python or
              JavaScript helps, but is not required.
            </p>
            <div class="tags">
              <span class="tag">No advanced math</span>
              <span class="tag">No coding required</span>
              <span class="tag">Beginner friendly</span>
            </div>
          </section>

          <div class="lessons-container">
            <h3 class="lessons-title">Course Lessons</h3>
            <!-- Course Lessons --->
            <div class="lesson-item" data-lesson="1">
              <div class="lesson-header">
                <div class="lesson-number">01</div>
                <div class="lesson-content">
                  <h4>Fairness from Data to Decisions</h4>
                  <p>
                    Measuring and mitigating bias in real workflows
                  </p>
                </div>
                <div class="lesson-status">
                  <i class="fas fa-lock-open"></i>
                </div>
              </div>
              <div class="lesson-details">
                <div class="lesson-meta">
                  <span><i class="fas fa-clock"></i> 8 min</span>
                  <span><i class="fas fa-file-text"></i> Notes</span>
                </div>
                <div class="lesson-preview">
                  <p>
                    Bias creeps in through datasets (sampling, labeling), features (proxies for protected attributes), and 
decision thresholds (different error costs across groups). A practical workflow is: define harm and 
stakeholders → choose fairness metrics aligned to context → run disaggregated evaluation (by 
subgroup) → mitigate via data balancing/reweighting, algorithmic changes (e.g., constraints for 
equalized odds), or post-processing (group-aware thresholds) → monitor drift over time. Remember 
that metrics trade off: demographic parity equalizes positive rates, while equalized odds equalizes error 
rates—pick based on the real-world duty of care (e.g., screening vs. adjudication). Document decisions 
and residual risks
                  </p>
                  <div class="callout neutral">
                    <strong>Key terms:</strong> demographic parity, equalized odds, calibration, subgroup analysis, post-processing
                  </div>
                </div>
              </div>
            </div>

            <div class="lesson-item" data-lesson="2">
              <div class="lesson-header">
                <div class="lesson-number">02</div>
                <div class="lesson-content">
                  <h4>Privacy & Data Governance by Design</h4>
                  <p>
                    Protecting people while preserving utility
                  </p>
                </div>
                <div class="lesson-status">
                  <i class="fas fa-lock-open"></i>
                </div>
              </div>
              <div class="lesson-details">
                <div class="lesson-meta">
                  <span><i class="fas fa-clock"></i> 6 min</span>
                  <span><i class="fas fa-file-text"></i> Notes</span>
                </div>
                <div class="lesson-preview">
                  <p>
                    Build around data minimization (collect only what you need), purpose limitation (no surprise uses), and 
secure lifecycle (ingestion → storage → access → deletion). Technical safeguards include differential 
privacy (adding calibrated noise so single records have limited influence), federated learning (train 
where data lives), and secure aggregation or confidential computing to reduce exposure. Beware 
“anonymous” data—linkage attacks can re-identify rows. Track lineage and consent; log who accessed 
what and why. When generating synthetic data, validate that it doesn’t memorize individuals 
(membership inference tests). Make privacy impact assessments routine, not exceptional.
                  </p>
                  <div class="callout neutral">
                    <strong>Key terms:</strong> differential privacy (ε), federated learning, secure aggregation, data minimization, lineage
                  </div>
                </div>
              </div>
            </div>

            <div class="lesson-item" data-lesson="3">
              <div class="lesson-header">
                <div class="lesson-number">03</div>
                <div class="lesson-content">
                  <h4>
                    Transparency, Explainability & Accountability
                  </h4>
                  <p>
                    Transparency is more than a one-time disclosure. Publish Model Cards (intended use, training data 
sources, metrics by subgroup, known limitations) and Datasheets for Datasets (collection process, 
consent, licensing, caveats). Maintain decision logs (inputs, versioned model, thresholds) for auditability 
and incident response. Use explainability responsibly: local methods (e.g., SHAP/LIME) can aid 
debugging, but don’t over-promise causal truth; pair explanations with user education and uncertainty 
ranges. Define escalation paths: who pauses a model, how rollbacks work, and what remediation looks 
like for affected users
                  </p>
                </div>
                <div class="lesson-status">
                  <i class="fas fa-lock-open"></i>
                </div>
              </div>
              <div class="lesson-details">
                <div class="lesson-meta">
                  <span><i class="fas fa-clock"></i> 10 min</span>
                  <span><i class="fas fa-file-text"></i> Notes</span>
                </div>
                <div class="lesson-preview">
                  <div class="callout neutral">
                    <strong>Key terms:</strong> model card, datasheet, audit trail, SHAP/LIME, uncertainty disclosure
                  </div>
                </div>
              </div>
            </div>

            <div class="lesson-item" data-lesson="4">
              <div class="lesson-header">
                <div class="lesson-number">04</div>
                <div class="lesson-content">
                  <h4>Safety, Alignment & Misuse Prevention</h4>
                  <p>From red-teaming to runtime safeguards</p>
                </div>
                <div class="lesson-status">
                  <i class="fas fa-lock-open"></i>
                </div>
              </div>
              <div class="lesson-details">
                <div class="lesson-meta">
                  <span><i class="fas fa-clock"></i> 7 min</span>
                  <span><i class="fas fa-file-text"></i> Notes</span>
                </div>
                <div class="lesson-preview">
                  <p>
                    Operational safety blends pre-deployment testing with live defenses. Red-team models to probe for 
harmful content, data exfiltration, jailbreaks, prompt injection, or privacy leaks. Align models with policy 
via instruction tuning and refusal/deflection strategies; layer content filters, rate limiting, and abuse 
detection in production. For connected systems and agents, constrain tools (principle of least privilege), 
validate outputs (grounding/verification), and add human-in-the-loop for high-impact actions. 
Continuously monitor for drift and incidents; create a lightweight Safety Review checklist for every 
change (new data, new prompt, new integration).
                  </p>
                  <div class="callout neutral">
                    <strong>Key terms:</strong> red-teaming, alignment, content filtering, prompt injection, least privilege.
                  </div>
                </div>
              </div>
            </div>

            <div class="lesson-item" data-lesson="5">
              <div class="lesson-header">
                <div class="lesson-number">05</div>
                <div class="lesson-content">
                  <h4>The Near Future of AI—Trends You Can Us</h4>
                  <p>What to build, how to evaluate, and where risks shif</p>
                </div>
                <div class="lesson-status">
                  <i class="fas fa-lock-open"></i>
                </div>
              </div>
              <div class="lesson-details">
                <div class="lesson-meta">
                  <span><i class="fas fa-clock"></i> 12 min</span>
                  <span><i class="fas fa-file-text"></i> Notes</span>
                </div>
                <div class="lesson-preview">
                  <p>
                   Three impactful shifts: (1) Retrieval-Augmented Generation (RAG) to ground outputs in your sources, 
reducing hallucinations and enabling citations; invest in document chunking, metadata, and evaluation 
beyond string-match. (2) On-device/edge models for privacy, lower latency, and resilience; plan for 
model quantization and fallback paths. (3) Agentic workflows that chain tools and tasks; require 
guardrails, state inspection, and sandboxed execution. Expect stronger sustainability pressures—
optimize with distillation, quantization, caching, and scheduled batch jobs. Evaluation must evolve: add 
task-specific checklists, human ratings, and safety benchmarks alongside accuracy.
                  </p>
                  <div class="callout neutral">
                    <strong>Key terms:</strong> RAG, grounding, quantization, distillation, agent sandboxing
                  </div>
                </div>
              </div>
            </div>


            <!-- Module summary -->
            <div class="lesson-item" data-lesson="12">
              <div class="lesson-header">
                <div class="lesson-number">12</div>
                <div class="lesson-content">
                  <h4>Module Summary</h4>
                  <p>
                    You can now explain what AI is, how the Turing Test relates
                    to intelligence, and how AI evolved from expert systems to
                    modern deep learning. You can distinguish ANI vs. AGI vs.
                    ASI, structure data into features and labels with proper
                    splits, pick between supervised/unsupervised/RL, evaluate
                    models with precision/recall/F1/ROC‑AUC, mitigate
                    overfitting, and reason about fairness, privacy and
                    transparency.
                  </p>
                  <p>
                    Next steps: explore the ML and Deep Learning modules, try a
                    small project (e.g., a classifier on tabular data), and
                    practice communicating model limitations responsibly.
                  </p>
                </div>
              </div>
            </div>
          </div>

          <section class="content-section" id="resources">
            <div class="section-header">
              <div class="section-icon">
                <i class="fas fa-book-open"></i>
              </div>
              <h3>Further Resources</h3>
            </div>
            <div class="resources-grid">
              <div class="resource-card">
                <div class="resource-icon">
                  <i class="fas fa-book"></i>
                </div>
                <h4>AI For Everyone</h4>
                <p>Andrew Ng's comprehensive overview course</p>
                <a
                  href="https://www.deeplearning.ai/courses/ai-for-everyone/"
                  class="resource-link"
                  >Learn More <i class="fas fa-arrow-right"></i
                ></a>
              </div>
              <div class="resource-card">
                <div class="resource-icon">
                  <i class="fas fa-code"></i>
                </div>
                <h4>scikit-learn</h4>
                <p>Beginner‑friendly machine learning API</p>
                <a
                  href="https://scikit-learn.org/stable/index.html"
                  class="resource-link"
                  >Learn More <i class="fas fa-arrow-right"></i
                ></a>
              </div>
            </div>
          </section>
        </div>
      </div>

      <aside class="enroll toc">
        <div class="toc-downloads">
          <h4>Course Materials</h4>
          <div class="download-item">
            <i class="fa-solid fa-file-lines"></i>
            <span>Summary notes (PDF)</span>
            <a
              class="download-btn download-notes"
              href="../materials/ai-foundations-summary.pdf"
              download
              aria-label="Download summary notes PDF"
              >Download</a
            >
          </div>
          <div class="download-item">
            <i class="fa-solid fa-file-code"></i>
            <span>Sample code (JS)</span>
            <a
              class="download-btn"
              href="../materials/ai-foundations-sample.js"
              download
              aria-label="Download sample code JS"
            >
              Download
            </a>
          </div>
        </div>

        <div class="toc-info">
          <div class="info-item">
            <i class="fa-regular fa-clock"></i>
            <span>Estimated time: ~2 hours</span>
          </div>
        </div>
      </aside>
    </section>
    <footer>
      <div class="footer-bottom">
        <p>
          &copy; 2025 MaxAI |
          <a href="mailto:rachellwanggg@gmail.com">andrianateam.com</a>
        </p>
      </div>
    </footer>

    <script src="ai-ethics.js"></script>
  </body>
</html>
